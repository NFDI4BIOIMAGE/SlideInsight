{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f36e2d-dd6e-41d9-9ebd-d07c811d4a26",
   "metadata": {},
   "source": [
    "## Creating Text Embeddings to identify related slides\n",
    "This notebook is used to identify similar or related groups of slides within different pdf files. For this, we use a dictionary with Text-Slide pairs (which was created in the [first Notebook](https://github.com/NFDI4BIOIMAGE/SlideInsight/blob/main/Test_Models.ipynb)). \n",
    "\n",
    "To do so, we first load the dictionary from the .json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48084b44-e23a-43e2-938a-b6b50f1bbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load the YAML file containing the image paths and corresponding text\n",
    "with open(\"dict_slides_text.yml\", \"r\") as yaml_file:\n",
    "    slide_dict = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893d7c9-2f2c-45c3-8571-c31624de5fd4",
   "metadata": {},
   "source": [
    "### Pip install the model\n",
    "Here, the [mxbai-embed-large model](https://ollama.com/library/mxbai-embed-large) is used to create the embedding.\n",
    "\n",
    "`!pip install -U mixedbread-ai sentence-transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2b6847-80d8-4006-85f1-4ce17cfcbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cadb613-41ed-40a3-b225-220d0d47045a",
   "metadata": {},
   "source": [
    "A pandas DataFrame is created to save all important properties of each slide:\n",
    "- .pdf filename\n",
    "- Slide number\n",
    "- Text\n",
    "- .png filename\n",
    "- Embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce5e728e-3521-43e7-b5e7-58ab04ae6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data = []\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for png_filename, text in slide_dict.items():\n",
    "    # Get the PDF name and slide number from the filename\n",
    "    pdf_name = png_filename.split('_slide')[0]\n",
    "    \n",
    "    # Process only entries from the \"WhatIsOMERO\" PDF\n",
    "    if pdf_name == \"WhatIsOMERO\":\n",
    "        slide_number = int(png_filename.split('_slide')[-1].split('.png')[0])\n",
    "        \n",
    "        # Get embedding\n",
    "        embedding = model.encode(text)\n",
    "\n",
    "        page_data.append({\n",
    "            'pdf_filename': f'{pdf_name}.pdf',\n",
    "            'page_index': slide_number,\n",
    "            'text': text,\n",
    "            'png_filename': png_filename,\n",
    "            'embedding': embedding\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1221643-362f-447d-aad1-f7e97790f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc08570b-7cee-477e-915c-8873484f533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>I3D:bio OMERO user training slides\\nHOW TO USE...</td>\n",
       "      <td>WhatIsOMERO_slide1.png</td>\n",
       "      <td>[0.4003333, -0.33649126, 0.39981106, -0.473099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Disclaimer\\n• The following slides are intende...</td>\n",
       "      <td>WhatIsOMERO_slide2.png</td>\n",
       "      <td>[0.39082658, -0.28587455, 0.38830236, -0.37186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Research Data Management for Bioimage Data\\nat...</td>\n",
       "      <td>WhatIsOMERO_slide3.png</td>\n",
       "      <td>[0.18631458, -0.3715705, -0.016562128, -0.6950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>OMERO: An open-source software for image data ...</td>\n",
       "      <td>WhatIsOMERO_slide4.png</td>\n",
       "      <td>[0.1806397, -0.6081787, -0.6387917, -0.4824682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>From isolated data silos…\\np 5 ADD LOGO SMALL</td>\n",
       "      <td>WhatIsOMERO_slide5.png</td>\n",
       "      <td>[-0.44303596, -0.50006086, 0.52318454, -0.3337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>… to centralized, structured data management\\n...</td>\n",
       "      <td>WhatIsOMERO_slide6.png</td>\n",
       "      <td>[-0.16422987, -0.5776923, 0.6634136, -0.554668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>OMERO at the ADD INSTITUTE HERE\\nService provi...</td>\n",
       "      <td>WhatIsOMERO_slide7.png</td>\n",
       "      <td>[-0.62620574, 0.008420461, -0.89739054, -0.598...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>Advantages of using OMERO\\n• Organize your ori...</td>\n",
       "      <td>WhatIsOMERO_slide8.png</td>\n",
       "      <td>[0.030079262, 0.27903175, -0.33694014, -0.8887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>Contact\\nPlease review the additional informat...</td>\n",
       "      <td>WhatIsOMERO_slide9.png</td>\n",
       "      <td>[-0.23266867, -0.5224059, 0.050569788, -0.4461...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pdf_filename  page_index  \\\n",
       "0  WhatIsOMERO.pdf           1   \n",
       "1  WhatIsOMERO.pdf           2   \n",
       "2  WhatIsOMERO.pdf           3   \n",
       "3  WhatIsOMERO.pdf           4   \n",
       "4  WhatIsOMERO.pdf           5   \n",
       "5  WhatIsOMERO.pdf           6   \n",
       "6  WhatIsOMERO.pdf           7   \n",
       "7  WhatIsOMERO.pdf           8   \n",
       "8  WhatIsOMERO.pdf           9   \n",
       "\n",
       "                                                text            png_filename  \\\n",
       "0  I3D:bio OMERO user training slides\\nHOW TO USE...  WhatIsOMERO_slide1.png   \n",
       "1  Disclaimer\\n• The following slides are intende...  WhatIsOMERO_slide2.png   \n",
       "2  Research Data Management for Bioimage Data\\nat...  WhatIsOMERO_slide3.png   \n",
       "3  OMERO: An open-source software for image data ...  WhatIsOMERO_slide4.png   \n",
       "4      From isolated data silos…\\np 5 ADD LOGO SMALL  WhatIsOMERO_slide5.png   \n",
       "5  … to centralized, structured data management\\n...  WhatIsOMERO_slide6.png   \n",
       "6  OMERO at the ADD INSTITUTE HERE\\nService provi...  WhatIsOMERO_slide7.png   \n",
       "7  Advantages of using OMERO\\n• Organize your ori...  WhatIsOMERO_slide8.png   \n",
       "8  Contact\\nPlease review the additional informat...  WhatIsOMERO_slide9.png   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.4003333, -0.33649126, 0.39981106, -0.473099...  \n",
       "1  [0.39082658, -0.28587455, 0.38830236, -0.37186...  \n",
       "2  [0.18631458, -0.3715705, -0.016562128, -0.6950...  \n",
       "3  [0.1806397, -0.6081787, -0.6387917, -0.4824682...  \n",
       "4  [-0.44303596, -0.50006086, 0.52318454, -0.3337...  \n",
       "5  [-0.16422987, -0.5776923, 0.6634136, -0.554668...  \n",
       "6  [-0.62620574, 0.008420461, -0.89739054, -0.598...  \n",
       "7  [0.030079262, 0.27903175, -0.33694014, -0.8887...  \n",
       "8  [-0.23266867, -0.5224059, 0.050569788, -0.4461...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375fa65-7d48-4e0b-8893-13b52ea1f911",
   "metadata": {},
   "source": [
    "### Pip install UMAP\n",
    "Now, we perform a dimensionality reduction using the UMAP, to enable a simple 2D plotting of our datapoints (slides).\n",
    "\n",
    "`!pip install -U umap-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "923d0916-ae08-45c0-aa42-dba8314dbc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lea/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/home/lea/.local/lib/python3.10/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "      <th>UMAP0</th>\n",
       "      <th>UMAP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>I3D:bio OMERO user training slides\\nHOW TO USE...</td>\n",
       "      <td>WhatIsOMERO_slide1.png</td>\n",
       "      <td>[0.4003333, -0.33649126, 0.39981106, -0.473099...</td>\n",
       "      <td>22.988615</td>\n",
       "      <td>6.322064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Disclaimer\\n• The following slides are intende...</td>\n",
       "      <td>WhatIsOMERO_slide2.png</td>\n",
       "      <td>[0.39082658, -0.28587455, 0.38830236, -0.37186...</td>\n",
       "      <td>23.344933</td>\n",
       "      <td>5.576495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Research Data Management for Bioimage Data\\nat...</td>\n",
       "      <td>WhatIsOMERO_slide3.png</td>\n",
       "      <td>[0.18631458, -0.3715705, -0.016562128, -0.6950...</td>\n",
       "      <td>23.924927</td>\n",
       "      <td>6.251481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>OMERO: An open-source software for image data ...</td>\n",
       "      <td>WhatIsOMERO_slide4.png</td>\n",
       "      <td>[0.1806397, -0.6081787, -0.6387917, -0.4824682...</td>\n",
       "      <td>23.767023</td>\n",
       "      <td>6.962986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>From isolated data silos…\\np 5 ADD LOGO SMALL</td>\n",
       "      <td>WhatIsOMERO_slide5.png</td>\n",
       "      <td>[-0.44303596, -0.50006086, 0.52318454, -0.3337...</td>\n",
       "      <td>22.896355</td>\n",
       "      <td>7.774837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>… to centralized, structured data management\\n...</td>\n",
       "      <td>WhatIsOMERO_slide6.png</td>\n",
       "      <td>[-0.16422987, -0.5776923, 0.6634136, -0.554668...</td>\n",
       "      <td>22.525280</td>\n",
       "      <td>7.269181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>OMERO at the ADD INSTITUTE HERE\\nService provi...</td>\n",
       "      <td>WhatIsOMERO_slide7.png</td>\n",
       "      <td>[-0.62620574, 0.008420461, -0.89739054, -0.598...</td>\n",
       "      <td>24.787344</td>\n",
       "      <td>6.237605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>Advantages of using OMERO\\n• Organize your ori...</td>\n",
       "      <td>WhatIsOMERO_slide8.png</td>\n",
       "      <td>[0.030079262, 0.27903175, -0.33694014, -0.8887...</td>\n",
       "      <td>24.230747</td>\n",
       "      <td>7.502076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>Contact\\nPlease review the additional informat...</td>\n",
       "      <td>WhatIsOMERO_slide9.png</td>\n",
       "      <td>[-0.23266867, -0.5224059, 0.050569788, -0.4461...</td>\n",
       "      <td>24.280399</td>\n",
       "      <td>5.510377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pdf_filename  page_index  \\\n",
       "0  WhatIsOMERO.pdf           1   \n",
       "1  WhatIsOMERO.pdf           2   \n",
       "2  WhatIsOMERO.pdf           3   \n",
       "3  WhatIsOMERO.pdf           4   \n",
       "4  WhatIsOMERO.pdf           5   \n",
       "5  WhatIsOMERO.pdf           6   \n",
       "6  WhatIsOMERO.pdf           7   \n",
       "7  WhatIsOMERO.pdf           8   \n",
       "8  WhatIsOMERO.pdf           9   \n",
       "\n",
       "                                                text            png_filename  \\\n",
       "0  I3D:bio OMERO user training slides\\nHOW TO USE...  WhatIsOMERO_slide1.png   \n",
       "1  Disclaimer\\n• The following slides are intende...  WhatIsOMERO_slide2.png   \n",
       "2  Research Data Management for Bioimage Data\\nat...  WhatIsOMERO_slide3.png   \n",
       "3  OMERO: An open-source software for image data ...  WhatIsOMERO_slide4.png   \n",
       "4      From isolated data silos…\\np 5 ADD LOGO SMALL  WhatIsOMERO_slide5.png   \n",
       "5  … to centralized, structured data management\\n...  WhatIsOMERO_slide6.png   \n",
       "6  OMERO at the ADD INSTITUTE HERE\\nService provi...  WhatIsOMERO_slide7.png   \n",
       "7  Advantages of using OMERO\\n• Organize your ori...  WhatIsOMERO_slide8.png   \n",
       "8  Contact\\nPlease review the additional informat...  WhatIsOMERO_slide9.png   \n",
       "\n",
       "                                           embedding      UMAP0     UMAP1  \n",
       "0  [0.4003333, -0.33649126, 0.39981106, -0.473099...  22.988615  6.322064  \n",
       "1  [0.39082658, -0.28587455, 0.38830236, -0.37186...  23.344933  5.576495  \n",
       "2  [0.18631458, -0.3715705, -0.016562128, -0.6950...  23.924927  6.251481  \n",
       "3  [0.1806397, -0.6081787, -0.6387917, -0.4824682...  23.767023  6.962986  \n",
       "4  [-0.44303596, -0.50006086, 0.52318454, -0.3337...  22.896355  7.774837  \n",
       "5  [-0.16422987, -0.5776923, 0.6634136, -0.554668...  22.525280  7.269181  \n",
       "6  [-0.62620574, 0.008420461, -0.89739054, -0.598...  24.787344  6.237605  \n",
       "7  [0.030079262, 0.27903175, -0.33694014, -0.8887...  24.230747  7.502076  \n",
       "8  [-0.23266867, -0.5224059, 0.050569788, -0.4461...  24.280399  5.510377  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Convert embedding vectors to numpy array for UMAP\n",
    "embeddings = np.array(df['embedding'].tolist())\n",
    "\n",
    "# Apply UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "df['UMAP0'] = umap_embeddings[:, 0]\n",
    "df['UMAP1'] = umap_embeddings[:, 1]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6dc3c-d2f2-49fa-88d3-7aa8d3b3c675",
   "metadata": {},
   "source": [
    "### Interactively Plotting Slides and Embedding\n",
    "In the final step, we can compare different groups of slides and their content.\n",
    "\n",
    "- The plot on the right shows the 2D representation of the Embedding. With drawing a circle around datapoints you can have a look at their content at the left.\n",
    "- Slides with similar content, regarding their text, should have similar vector representations and should appear close to each other in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b5b50a8-b34d-4a32-ae63-859c42a48054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(df):\n",
    "    images = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = row['png_filename']  # Access the correct row value\n",
    "        img = imread(img_path)  # Read the image\n",
    "        images.append(img)\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7325175-3ebf-4ac1-9672-5742d7e8d5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04164249a9964aa0b04500f1b2dc8649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=3…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stackview\n",
    "from skimage.io import imread\n",
    "\n",
    "stackview.sliceplot(df, get_images(df), column_x=\"UMAP0\", column_y=\"UMAP1\", zoom_factor=1.5, zoom_spline_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31c416-ed2b-4830-bc15-bec1bd62f1be",
   "metadata": {},
   "source": [
    "### Testing the plotting with a larger Slide Deck\n",
    "\n",
    "To have a better idea, how this plotting is working, we now use a larger sample of PDFs from the [training material](https://zenodo.org/records/14030307) collection about Bio-Image Analysis from Robert Haase (licensed under CC-BY 4.0). We also use his implementation to [download the PDFs from Zenodo](https://github.com/haesleinhuepf/stackview/blob/main/docs/sliceplot_datagen.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de4995ee-8b76-4322-a71e-08ba66e21d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': '12623730_14_Summary.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/14_Summary.pdf/content'},\n",
       " {'filename': '12623730_10_function_calling.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/10_function_calling.pdf/content'},\n",
       " {'filename': '12623730_11_prompteng_rag_finetuning.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/11_prompteng_rag_finetuning.pdf/content'},\n",
       " {'filename': '12623730_12_Vision_models.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/12_Vision_models.pdf/content'},\n",
       " {'filename': '12623730_09_Deep_Learning.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/09_Deep_Learning.pdf/content'},\n",
       " {'filename': '12623730_08_Sup_Unsup_Machine_Learning.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/08_Sup_Unsup_Machine_Learning.pdf/content'},\n",
       " {'filename': '12623730_03_RSM_Image_Processing.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/03_RSM_Image_Processing.pdf/content'},\n",
       " {'filename': '12623730_01_Introduction_BIDS_2024.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/01_Introduction_BIDS_2024.pdf/content'},\n",
       " {'filename': '12623730_13_quality_assurance.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/13_quality_assurance.pdf/content'},\n",
       " {'filename': '12623730_02_Introduction_RDM_2024.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/02_Introduction_RDM_2024.pdf/content'},\n",
       " {'filename': '12623730_04_Image_segmentation.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/04_Image_segmentation.pdf/content'},\n",
       " {'filename': '12623730_05_Surface_Recon_QA.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/05_Surface_Recon_QA.pdf/content'},\n",
       " {'filename': '12623730_07_distributed_gpu_computing.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/07_distributed_gpu_computing.pdf/content'},\n",
       " {'filename': '12623730_06_Chatbots.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/06_Chatbots.pdf/content'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdfs_from_zenodo(record_id):\n",
    "    \"\"\"Download PDFs from Zenodo record.\"\"\"\n",
    "    base_url = f\"https://zenodo.org/api/records/{record_id}\"\n",
    "    response = requests.get(base_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if not os.path.exists('downloads'):\n",
    "        os.makedirs('downloads')\n",
    "    \n",
    "    files_info = []\n",
    "    for file in data['files']:\n",
    "        if file['key'].endswith('.pdf'):\n",
    "            download_url = file['links']['self']\n",
    "            filename = record_id + \"_\" + file['key']\n",
    "            filepath = os.path.join('downloads', filename)\n",
    "\n",
    "            if not os.path.exists(filepath):\n",
    "                # Download file\n",
    "                response = requests.get(download_url)\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "            \n",
    "            files_info.append({'filename': filename, 'url': download_url})\n",
    "    \n",
    "    return files_info\n",
    "\n",
    "\n",
    "# Download PDFs\n",
    "files_info = download_pdfs_from_zenodo('12623730')\n",
    "files_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e1a9a-fabd-4898-a76b-5961aefa181c",
   "metadata": {},
   "source": [
    "## Saving all Slides from the pdfs to .png Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45eabde6-3356-4637-9a18-dd34b77ccc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pdf_utilities import load_pdf, save_images, text_extraction, text_extract_from_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba90b7d-e50c-48f8-9f3a-086b693d3bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: downloads/12623730_10_function_calling.pdf\n",
      "Images for 12623730_10_function_calling.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_09_Deep_Learning.pdf\n",
      "Images for 12623730_09_Deep_Learning.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_06_Chatbots.pdf\n",
      "Images for 12623730_06_Chatbots.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_05_Surface_Recon_QA.pdf\n",
      "Images for 12623730_05_Surface_Recon_QA.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_08_Sup_Unsup_Machine_Learning.pdf\n",
      "Images for 12623730_08_Sup_Unsup_Machine_Learning.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_04_Image_segmentation.pdf\n",
      "Images for 12623730_04_Image_segmentation.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_02_Introduction_RDM_2024.pdf\n",
      "Images for 12623730_02_Introduction_RDM_2024.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_12_Vision_models.pdf\n",
      "Images for 12623730_12_Vision_models.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_11_prompteng_rag_finetuning.pdf\n",
      "Images for 12623730_11_prompteng_rag_finetuning.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_01_Introduction_BIDS_2024.pdf\n",
      "Images for 12623730_01_Introduction_BIDS_2024.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_13_quality_assurance.pdf\n",
      "Images for 12623730_13_quality_assurance.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_07_distributed_gpu_computing.pdf\n",
      "Images for 12623730_07_distributed_gpu_computing.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_03_RSM_Image_Processing.pdf\n",
      "Images for 12623730_03_RSM_Image_Processing.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_14_Summary.pdf\n",
      "Images for 12623730_14_Summary.pdf saved successfully in downloads/images.\n"
     ]
    }
   ],
   "source": [
    "downloads_folder = \"downloads\"\n",
    "images_folder = os.path.join(\"downloads\", \"images\")\n",
    "\n",
    "# Ensure the \"images\" folder exists\n",
    "os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over all files in the downloads folder\n",
    "for file_name in os.listdir(downloads_folder):\n",
    "    # Check if the file is a PDF\n",
    "    if file_name.lower().endswith('.pdf'):\n",
    "        pdf_path = os.path.join(downloads_folder, file_name)\n",
    "        print(f\"Processing PDF: {pdf_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Use the save_images function to save images in the \"images\" folder\n",
    "            save_images(filepath=images_folder, pdf=pdf_path, new_width=700)\n",
    "            print(f\"Images for {file_name} saved successfully in {images_folder}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e8596-d33a-42c8-88f8-c491d49c146f",
   "metadata": {},
   "source": [
    "## Extracting the text from each slide and save it to the dict_slides_text.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d34f7a-f031-411a-b6c6-490637656a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slides for 12623730_02_Introduction_RDM_2024 already processed. Skipping.\n",
      "Processing slides for 12623730_03_RSM_Image_Processing...\n",
      "Processing slides for 12623730_04_Image_segmentation...\n",
      "Processing slides for 12623730_05_Surface_Recon_QA...\n",
      "Processing slides for 12623730_08_Sup_Unsup_Machine_Learning...\n",
      "Slides for 12623730_01_Introduction_BIDS_2024 already processed. Skipping.\n",
      "Processing slides for 12623730_14_Summary...\n",
      "Processing slides for 12623730_11_prompteng_rag_finetuning...\n",
      "Processing slides for 12623730_07_distributed_gpu_computing...\n",
      "Processing slides for 12623730_06_Chatbots...\n",
      "Processing slides for 12623730_09_Deep_Learning...\n",
      "Processing slides for 12623730_10_function_calling...\n",
      "Processing slides for 12623730_13_quality_assurance...\n",
      "Processing slides for 12623730_12_Vision_models...\n"
     ]
    }
   ],
   "source": [
    "text_extract_from_pdfs(downloads_folder=\"downloads\", yaml_file_path=\"dict_slides_text.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81af41-7a03-4806-aacd-d1f3f4ddec65",
   "metadata": {},
   "source": [
    "## Creating the pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf40f07a-564e-4fe0-ae00-d9359a5b275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML file containing the image paths and corresponding text\n",
    "with open(\"dict_slides_text.yml\", \"r\") as yaml_file:\n",
    "    slide_dict = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cdd053-00de-480d-bb78-5d69fcd94af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795b0f18-2cce-45a1-988e-2ace9c78eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing slides for 12623730_02_Introduction_RDM_2024\n",
      "Finished processing slides for 12623730_01_Introduction_BIDS_2024\n",
      "Finished processing slides for 12623730_03_RSM_Image_Processing\n",
      "Finished processing slides for 12623730_04_Image_segmentation\n",
      "Finished processing slides for 12623730_05_Surface_Recon_QA\n",
      "Finished processing slides for 12623730_08_Sup_Unsup_Machine_Learning\n",
      "Finished processing slides for 12623730_14_Summary\n",
      "Finished processing slides for 12623730_11_prompteng_rag_finetuning\n",
      "Finished processing slides for 12623730_07_distributed_gpu_computing\n",
      "Finished processing slides for 12623730_06_Chatbots\n",
      "Finished processing slides for 12623730_09_Deep_Learning\n",
      "Finished processing slides for 12623730_10_function_calling\n",
      "Finished processing slides for 12623730_13_quality_assurance\n",
      "Finished processing slides for 12623730_12_Vision_models\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "page_data = []\n",
    "last_pdf_name = None # to keep track of processing\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for png_filename, text in slide_dict.items():\n",
    "    # Get the PDF name and slide number from the filename\n",
    "    pdf_path = png_filename.split('_slide')[0]\n",
    "    pdf_name = pdf_path.replace('downloads/', '')\n",
    "\n",
    "    if pdf_name != \"WhatIsOMERO\":\n",
    "        slide_number = int(png_filename.split('_slide')[-1].split('.png')[0])\n",
    "        cleaned_png_name = re.sub(r\"^downloads/\", \"\", png_filename)    \n",
    "        # Get embedding\n",
    "        embedding = model.encode(text)\n",
    "    \n",
    "        page_data.append({\n",
    "                'pdf_filename': f'{pdf_name}.pdf',\n",
    "                'page_index': slide_number,\n",
    "                'text': text,\n",
    "                'png_filename': cleaned_png_name,\n",
    "                'embedding': embedding\n",
    "        })\n",
    "        \n",
    "    # Print message only if the PDF name has changed to keep track of the already processed pdfs\n",
    "        if pdf_name != last_pdf_name:\n",
    "            print(f\"Finished processing slides for {pdf_name}\")\n",
    "            last_pdf_name = pdf_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84abc4a0-9923-4e16-b935-b9626afa4d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide1.png</td>\n",
       "      <td>[0.03979108, 0.2714794, 0.013242222, 0.1890877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Recap quiz\\n• We write good documentation to e...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide2.png</td>\n",
       "      <td>[0.47924232, -0.01590968, 0.15884666, 0.013915...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Recap quiz\\n• “Resolution” in microscopy imagi...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide3.png</td>\n",
       "      <td>[0.8939316, -0.8204742, 0.51319516, -0.0657548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>Research Data Management (RDM)\\n• All activiti...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide4.png</td>\n",
       "      <td>[0.04139501, 0.255146, -0.29497755, 0.16310011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>RDM Life Cycle\\nPlan\\n• Processes are\\nideally...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide5.png</td>\n",
       "      <td>[-0.24418333, 0.15344226, 0.20762181, 0.333282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>36</td>\n",
       "      <td>Accessing VLMs using Python\\nAPI not standardi...</td>\n",
       "      <td>12623730_12_Vision_models_slide36.png</td>\n",
       "      <td>[0.65550154, -0.06335969, -0.10102747, 0.25541...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>37</td>\n",
       "      <td>CENTER FOR SCALABLE DATA ANALYTICS AND\\nARTIFI...</td>\n",
       "      <td>12623730_12_Vision_models_slide37.png</td>\n",
       "      <td>[0.40174937, 0.5568686, -0.14620262, 0.3707969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>38</td>\n",
       "      <td>Exercise: Image generation\\nTry to identify an...</td>\n",
       "      <td>12623730_12_Vision_models_slide38.png</td>\n",
       "      <td>[0.8831491, 0.18154411, 0.16150065, 0.24324436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>39</td>\n",
       "      <td>Exercise: Image manipulation\\nInspect the imag...</td>\n",
       "      <td>12623730_12_Vision_models_slide39.png</td>\n",
       "      <td>[0.6330425, -0.1276842, 0.06782451, -0.1758888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>40</td>\n",
       "      <td>Exercise: Vision\\nAsk llava and gpt-4omni to d...</td>\n",
       "      <td>12623730_12_Vision_models_slide40.png</td>\n",
       "      <td>[1.0971026, -0.19714442, 0.015758421, -0.04753...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>863 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pdf_filename  page_index  \\\n",
       "0    12623730_02_Introduction_RDM_2024.pdf           1   \n",
       "1    12623730_02_Introduction_RDM_2024.pdf           2   \n",
       "2    12623730_02_Introduction_RDM_2024.pdf           3   \n",
       "3    12623730_02_Introduction_RDM_2024.pdf           4   \n",
       "4    12623730_02_Introduction_RDM_2024.pdf           5   \n",
       "..                                     ...         ...   \n",
       "858          12623730_12_Vision_models.pdf          36   \n",
       "859          12623730_12_Vision_models.pdf          37   \n",
       "860          12623730_12_Vision_models.pdf          38   \n",
       "861          12623730_12_Vision_models.pdf          39   \n",
       "862          12623730_12_Vision_models.pdf          40   \n",
       "\n",
       "                                                  text  \\\n",
       "0    CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...   \n",
       "1    Recap quiz\\n• We write good documentation to e...   \n",
       "2    Recap quiz\\n• “Resolution” in microscopy imagi...   \n",
       "3    Research Data Management (RDM)\\n• All activiti...   \n",
       "4    RDM Life Cycle\\nPlan\\n• Processes are\\nideally...   \n",
       "..                                                 ...   \n",
       "858  Accessing VLMs using Python\\nAPI not standardi...   \n",
       "859  CENTER FOR SCALABLE DATA ANALYTICS AND\\nARTIFI...   \n",
       "860  Exercise: Image generation\\nTry to identify an...   \n",
       "861  Exercise: Image manipulation\\nInspect the imag...   \n",
       "862  Exercise: Vision\\nAsk llava and gpt-4omni to d...   \n",
       "\n",
       "                                     png_filename  \\\n",
       "0    12623730_02_Introduction_RDM_2024_slide1.png   \n",
       "1    12623730_02_Introduction_RDM_2024_slide2.png   \n",
       "2    12623730_02_Introduction_RDM_2024_slide3.png   \n",
       "3    12623730_02_Introduction_RDM_2024_slide4.png   \n",
       "4    12623730_02_Introduction_RDM_2024_slide5.png   \n",
       "..                                            ...   \n",
       "858         12623730_12_Vision_models_slide36.png   \n",
       "859         12623730_12_Vision_models_slide37.png   \n",
       "860         12623730_12_Vision_models_slide38.png   \n",
       "861         12623730_12_Vision_models_slide39.png   \n",
       "862         12623730_12_Vision_models_slide40.png   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.03979108, 0.2714794, 0.013242222, 0.1890877...  \n",
       "1    [0.47924232, -0.01590968, 0.15884666, 0.013915...  \n",
       "2    [0.8939316, -0.8204742, 0.51319516, -0.0657548...  \n",
       "3    [0.04139501, 0.255146, -0.29497755, 0.16310011...  \n",
       "4    [-0.24418333, 0.15344226, 0.20762181, 0.333282...  \n",
       "..                                                 ...  \n",
       "858  [0.65550154, -0.06335969, -0.10102747, 0.25541...  \n",
       "859  [0.40174937, 0.5568686, -0.14620262, 0.3707969...  \n",
       "860  [0.8831491, 0.18154411, 0.16150065, 0.24324436...  \n",
       "861  [0.6330425, -0.1276842, 0.06782451, -0.1758888...  \n",
       "862  [1.0971026, -0.19714442, 0.015758421, -0.04753...  \n",
       "\n",
       "[863 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.DataFrame(page_data)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fbf7d-08fe-4622-b98d-807969c6cb84",
   "metadata": {},
   "source": [
    "## Perform Dimensionality Reduction by using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf3fc678-7671-4196-9ff2-8b8009da88fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lea/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "      <th>UMAP0</th>\n",
       "      <th>UMAP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide1.png</td>\n",
       "      <td>[0.03979108, 0.2714794, 0.013242222, 0.1890877...</td>\n",
       "      <td>5.162569</td>\n",
       "      <td>5.846556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Recap quiz\\n• We write good documentation to e...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide2.png</td>\n",
       "      <td>[0.47924232, -0.01590968, 0.15884666, 0.013915...</td>\n",
       "      <td>3.750810</td>\n",
       "      <td>6.237405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Recap quiz\\n• “Resolution” in microscopy imagi...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide3.png</td>\n",
       "      <td>[0.8939316, -0.8204742, 0.51319516, -0.0657548...</td>\n",
       "      <td>9.165031</td>\n",
       "      <td>7.279320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>Research Data Management (RDM)\\n• All activiti...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide4.png</td>\n",
       "      <td>[0.04139501, 0.255146, -0.29497755, 0.16310011...</td>\n",
       "      <td>3.806439</td>\n",
       "      <td>5.303634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12623730_02_Introduction_RDM_2024.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>RDM Life Cycle\\nPlan\\n• Processes are\\nideally...</td>\n",
       "      <td>12623730_02_Introduction_RDM_2024_slide5.png</td>\n",
       "      <td>[-0.24418333, 0.15344226, 0.20762181, 0.333282...</td>\n",
       "      <td>3.760873</td>\n",
       "      <td>5.245977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>36</td>\n",
       "      <td>Accessing VLMs using Python\\nAPI not standardi...</td>\n",
       "      <td>12623730_12_Vision_models_slide36.png</td>\n",
       "      <td>[0.65550154, -0.06335969, -0.10102747, 0.25541...</td>\n",
       "      <td>4.353026</td>\n",
       "      <td>7.572898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>37</td>\n",
       "      <td>CENTER FOR SCALABLE DATA ANALYTICS AND\\nARTIFI...</td>\n",
       "      <td>12623730_12_Vision_models_slide37.png</td>\n",
       "      <td>[0.40174937, 0.5568686, -0.14620262, 0.3707969...</td>\n",
       "      <td>6.332311</td>\n",
       "      <td>6.308408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>38</td>\n",
       "      <td>Exercise: Image generation\\nTry to identify an...</td>\n",
       "      <td>12623730_12_Vision_models_slide38.png</td>\n",
       "      <td>[0.8831491, 0.18154411, 0.16150065, 0.24324436...</td>\n",
       "      <td>7.751333</td>\n",
       "      <td>8.167833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>39</td>\n",
       "      <td>Exercise: Image manipulation\\nInspect the imag...</td>\n",
       "      <td>12623730_12_Vision_models_slide39.png</td>\n",
       "      <td>[0.6330425, -0.1276842, 0.06782451, -0.1758888...</td>\n",
       "      <td>10.294657</td>\n",
       "      <td>8.945478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>12623730_12_Vision_models.pdf</td>\n",
       "      <td>40</td>\n",
       "      <td>Exercise: Vision\\nAsk llava and gpt-4omni to d...</td>\n",
       "      <td>12623730_12_Vision_models_slide40.png</td>\n",
       "      <td>[1.0971026, -0.19714442, 0.015758421, -0.04753...</td>\n",
       "      <td>7.740471</td>\n",
       "      <td>8.773547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>863 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pdf_filename  page_index  \\\n",
       "0    12623730_02_Introduction_RDM_2024.pdf           1   \n",
       "1    12623730_02_Introduction_RDM_2024.pdf           2   \n",
       "2    12623730_02_Introduction_RDM_2024.pdf           3   \n",
       "3    12623730_02_Introduction_RDM_2024.pdf           4   \n",
       "4    12623730_02_Introduction_RDM_2024.pdf           5   \n",
       "..                                     ...         ...   \n",
       "858          12623730_12_Vision_models.pdf          36   \n",
       "859          12623730_12_Vision_models.pdf          37   \n",
       "860          12623730_12_Vision_models.pdf          38   \n",
       "861          12623730_12_Vision_models.pdf          39   \n",
       "862          12623730_12_Vision_models.pdf          40   \n",
       "\n",
       "                                                  text  \\\n",
       "0    CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...   \n",
       "1    Recap quiz\\n• We write good documentation to e...   \n",
       "2    Recap quiz\\n• “Resolution” in microscopy imagi...   \n",
       "3    Research Data Management (RDM)\\n• All activiti...   \n",
       "4    RDM Life Cycle\\nPlan\\n• Processes are\\nideally...   \n",
       "..                                                 ...   \n",
       "858  Accessing VLMs using Python\\nAPI not standardi...   \n",
       "859  CENTER FOR SCALABLE DATA ANALYTICS AND\\nARTIFI...   \n",
       "860  Exercise: Image generation\\nTry to identify an...   \n",
       "861  Exercise: Image manipulation\\nInspect the imag...   \n",
       "862  Exercise: Vision\\nAsk llava and gpt-4omni to d...   \n",
       "\n",
       "                                     png_filename  \\\n",
       "0    12623730_02_Introduction_RDM_2024_slide1.png   \n",
       "1    12623730_02_Introduction_RDM_2024_slide2.png   \n",
       "2    12623730_02_Introduction_RDM_2024_slide3.png   \n",
       "3    12623730_02_Introduction_RDM_2024_slide4.png   \n",
       "4    12623730_02_Introduction_RDM_2024_slide5.png   \n",
       "..                                            ...   \n",
       "858         12623730_12_Vision_models_slide36.png   \n",
       "859         12623730_12_Vision_models_slide37.png   \n",
       "860         12623730_12_Vision_models_slide38.png   \n",
       "861         12623730_12_Vision_models_slide39.png   \n",
       "862         12623730_12_Vision_models_slide40.png   \n",
       "\n",
       "                                             embedding      UMAP0     UMAP1  \n",
       "0    [0.03979108, 0.2714794, 0.013242222, 0.1890877...   5.162569  5.846556  \n",
       "1    [0.47924232, -0.01590968, 0.15884666, 0.013915...   3.750810  6.237405  \n",
       "2    [0.8939316, -0.8204742, 0.51319516, -0.0657548...   9.165031  7.279320  \n",
       "3    [0.04139501, 0.255146, -0.29497755, 0.16310011...   3.806439  5.303634  \n",
       "4    [-0.24418333, 0.15344226, 0.20762181, 0.333282...   3.760873  5.245977  \n",
       "..                                                 ...        ...       ...  \n",
       "858  [0.65550154, -0.06335969, -0.10102747, 0.25541...   4.353026  7.572898  \n",
       "859  [0.40174937, 0.5568686, -0.14620262, 0.3707969...   6.332311  6.308408  \n",
       "860  [0.8831491, 0.18154411, 0.16150065, 0.24324436...   7.751333  8.167833  \n",
       "861  [0.6330425, -0.1276842, 0.06782451, -0.1758888...  10.294657  8.945478  \n",
       "862  [1.0971026, -0.19714442, 0.015758421, -0.04753...   7.740471  8.773547  \n",
       "\n",
       "[863 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Convert embedding vectors to numpy array for UMAP\n",
    "embeddings = np.array(df_all['embedding'].tolist())\n",
    "\n",
    "# Apply UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "df_all['UMAP0'] = umap_embeddings[:, 0]\n",
    "df_all['UMAP1'] = umap_embeddings[:, 1]\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1316e-30f3-47ac-a5f2-d103bbc29547",
   "metadata": {},
   "source": [
    "As this file can get quite big, depending on the number of pdfs we feed in, it might be helpful to store it online rather than on disc. A good option would be for example to store it with Huggingface.\n",
    "To do so you first need to install this option with:\n",
    "\n",
    "`pip install datasets`\n",
    "\n",
    "You also have to create a [Huggingface Token](https://huggingface.co/docs/hub/security-tokens) and set this as a environment variable. To get more information on how to do that, that check the [ReadMe](https://github.com/NFDI4BIOIMAGE/SlideInsight/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f5ba964-b778-438f-9818-2e794af2bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate your current session\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3542185-dcb4-4e47-9b05-c1f47596bbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pdf_filename', 'page_index', 'text', 'png_filename', 'embedding', 'UMAP0', 'UMAP1'],\n",
       "    num_rows: 863\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Create a Hugging Face dataset from the DataFrame\n",
    "dataset = Dataset.from_pandas(df_all)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93b5bed4-bf95-4633-bb9a-4e80dc1875e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e57c25872c4ea0b316f3f64c28de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dc16ab17e94d828181e0b1b634709b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/lea-33/SlightInsight_Data/commit/d5fa0632c8785c93fb6a33d11511ef1533565de0', commit_message='Upload dataset', commit_description='', oid='d5fa0632c8785c93fb6a33d11511ef1533565de0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/lea-33/SlightInsight_Data', endpoint='https://huggingface.co', repo_type='dataset', repo_id='lea-33/SlightInsight_Data'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the dataset to huggingface\n",
    "dataset.push_to_hub(\"lea-33/SlightInsight_Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c576db9b-4b8f-4445-b1e0-871224004620",
   "metadata": {},
   "source": [
    "To later on load the dataset again, you can use:\n",
    "\n",
    "`from datasets import load_dataset`\n",
    "\n",
    "`dataset2_name = \"lea-33/SlightInsight_Data\"`\n",
    "\n",
    "`dataset2 = load_dataset(dataset2_name, split=\"all\")`\n",
    "\n",
    "`df2 = dataset2.to_pandas()`\n",
    "\n",
    "`df2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b0ff383-0bf4-4569-8efc-064a34c47a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(df, images_folder=\"downloads/images\"):\n",
    "    images = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(images_folder, row['png_filename'])  # Access the correct row value\n",
    "        img = imread(img_path)  # Read the image\n",
    "        images.append(img)\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e8b93c-9f7b-4a11-bc7b-2d8bfab141b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10f6776a5e0400cb5950e3942c02b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=3…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stackview\n",
    "from skimage.io import imread\n",
    "import os\n",
    "stackview.sliceplot(df_all, get_all_images(df_all), column_x=\"UMAP0\", column_y=\"UMAP1\", zoom_factor=1, zoom_spline_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3171369-27d5-4c39-81ee-da8dd58debd4",
   "metadata": {},
   "source": [
    "### Optionally: Deleting the pdfs and images again from your local disc (by deleting the whole downloads folder that was just created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f89e87-10f7-4c2f-9685-5f839117d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6434e314-a75a-4747-8350-521963ed8c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted the folder: downloads\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = \"downloads\"\n",
    "\n",
    "try:\n",
    "    # Delete the entire folder and its contents\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"Deleted the folder: {folder_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting folder {folder_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
