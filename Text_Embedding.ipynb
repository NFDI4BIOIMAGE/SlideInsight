{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f36e2d-dd6e-41d9-9ebd-d07c811d4a26",
   "metadata": {},
   "source": [
    "## Creating Text Embeddings to identify related slides\n",
    "This notebook is used to identify similar or related groups of slides within different pdf files. For this, we use a dictionary with Text-Slide pairs (which was created in the [first Notebook](https://github.com/NFDI4BIOIMAGE/SlideInsight/blob/main/Test_Models.ipynb)). \n",
    "\n",
    "To do so, we first load the dictionary from the .json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48084b44-e23a-43e2-938a-b6b50f1bbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load the YAML file containing the image paths and corresponding text\n",
    "with open(\"dict_slides_text.yml\", \"r\") as yaml_file:\n",
    "    slide_dict = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893d7c9-2f2c-45c3-8571-c31624de5fd4",
   "metadata": {},
   "source": [
    "### Pip install the model\n",
    "Here, the [mxbai-embed-large model](https://ollama.com/library/mxbai-embed-large) is used to create the embedding.\n",
    "\n",
    "`!pip install -U mixedbread-ai sentence-transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2b6847-80d8-4006-85f1-4ce17cfcbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cadb613-41ed-40a3-b225-220d0d47045a",
   "metadata": {},
   "source": [
    "A pandas DataFrame is created to save all important properties of each slide:\n",
    "- .pdf filename\n",
    "- Slide number\n",
    "- Text\n",
    "- .png filename\n",
    "- Embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5e728e-3521-43e7-b5e7-58ab04ae6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data = []\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for png_filename, text in slide_dict.items():\n",
    "    # Get the PDF name and slide number from the filename\n",
    "    pdf_name = png_filename.split('_slide')[0]\n",
    "    \n",
    "    # Process only entries from the \"WhatIsOMERO\" PDF\n",
    "    if pdf_name == \"WhatIsOMERO\":\n",
    "        slide_number = int(png_filename.split('_slide')[-1].split('.png')[0])\n",
    "        \n",
    "        # Get embedding\n",
    "        embedding = model.encode(text)\n",
    "\n",
    "        page_data.append({\n",
    "            'pdf_filename': f'{pdf_name}.pdf',\n",
    "            'page_index': slide_number,\n",
    "            'text': text,\n",
    "            'png_filename': png_filename,\n",
    "            'embedding': embedding\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1221643-362f-447d-aad1-f7e97790f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc08570b-7cee-477e-915c-8873484f533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>I3D:bio OMERO user training slides\\nHOW TO USE...</td>\n",
       "      <td>WhatIsOMERO_slide1.png</td>\n",
       "      <td>[0.4003333, -0.33649126, 0.39981106, -0.473099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Disclaimer\\n• The following slides are intende...</td>\n",
       "      <td>WhatIsOMERO_slide2.png</td>\n",
       "      <td>[0.39082658, -0.28587455, 0.38830236, -0.37186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Research Data Management for Bioimage Data\\nat...</td>\n",
       "      <td>WhatIsOMERO_slide3.png</td>\n",
       "      <td>[0.18631458, -0.3715705, -0.016562128, -0.6950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>OMERO: An open-source software for image data ...</td>\n",
       "      <td>WhatIsOMERO_slide4.png</td>\n",
       "      <td>[0.1806397, -0.6081787, -0.6387917, -0.4824682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>From isolated data silos…\\np 5 ADD LOGO SMALL</td>\n",
       "      <td>WhatIsOMERO_slide5.png</td>\n",
       "      <td>[-0.44303596, -0.50006086, 0.52318454, -0.3337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>… to centralized, structured data management\\n...</td>\n",
       "      <td>WhatIsOMERO_slide6.png</td>\n",
       "      <td>[-0.16422987, -0.5776923, 0.6634136, -0.554668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>OMERO at the ADD INSTITUTE HERE\\nService provi...</td>\n",
       "      <td>WhatIsOMERO_slide7.png</td>\n",
       "      <td>[-0.62620574, 0.008420461, -0.89739054, -0.598...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>Advantages of using OMERO\\n• Organize your ori...</td>\n",
       "      <td>WhatIsOMERO_slide8.png</td>\n",
       "      <td>[0.030079262, 0.27903175, -0.33694014, -0.8887...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>Contact\\nPlease review the additional informat...</td>\n",
       "      <td>WhatIsOMERO_slide9.png</td>\n",
       "      <td>[-0.23266867, -0.5224059, 0.050569788, -0.4461...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pdf_filename  page_index  \\\n",
       "0  WhatIsOMERO.pdf           1   \n",
       "1  WhatIsOMERO.pdf           2   \n",
       "2  WhatIsOMERO.pdf           3   \n",
       "3  WhatIsOMERO.pdf           4   \n",
       "4  WhatIsOMERO.pdf           5   \n",
       "5  WhatIsOMERO.pdf           6   \n",
       "6  WhatIsOMERO.pdf           7   \n",
       "7  WhatIsOMERO.pdf           8   \n",
       "8  WhatIsOMERO.pdf           9   \n",
       "\n",
       "                                                text            png_filename  \\\n",
       "0  I3D:bio OMERO user training slides\\nHOW TO USE...  WhatIsOMERO_slide1.png   \n",
       "1  Disclaimer\\n• The following slides are intende...  WhatIsOMERO_slide2.png   \n",
       "2  Research Data Management for Bioimage Data\\nat...  WhatIsOMERO_slide3.png   \n",
       "3  OMERO: An open-source software for image data ...  WhatIsOMERO_slide4.png   \n",
       "4      From isolated data silos…\\np 5 ADD LOGO SMALL  WhatIsOMERO_slide5.png   \n",
       "5  … to centralized, structured data management\\n...  WhatIsOMERO_slide6.png   \n",
       "6  OMERO at the ADD INSTITUTE HERE\\nService provi...  WhatIsOMERO_slide7.png   \n",
       "7  Advantages of using OMERO\\n• Organize your ori...  WhatIsOMERO_slide8.png   \n",
       "8  Contact\\nPlease review the additional informat...  WhatIsOMERO_slide9.png   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.4003333, -0.33649126, 0.39981106, -0.473099...  \n",
       "1  [0.39082658, -0.28587455, 0.38830236, -0.37186...  \n",
       "2  [0.18631458, -0.3715705, -0.016562128, -0.6950...  \n",
       "3  [0.1806397, -0.6081787, -0.6387917, -0.4824682...  \n",
       "4  [-0.44303596, -0.50006086, 0.52318454, -0.3337...  \n",
       "5  [-0.16422987, -0.5776923, 0.6634136, -0.554668...  \n",
       "6  [-0.62620574, 0.008420461, -0.89739054, -0.598...  \n",
       "7  [0.030079262, 0.27903175, -0.33694014, -0.8887...  \n",
       "8  [-0.23266867, -0.5224059, 0.050569788, -0.4461...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375fa65-7d48-4e0b-8893-13b52ea1f911",
   "metadata": {},
   "source": [
    "### Pip install UMAP\n",
    "Now, we perform a dimensionality reduction using the UMAP, to enable a simple 2D plotting of our datapoints (slides).\n",
    "\n",
    "`!pip install -U umap-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923d0916-ae08-45c0-aa42-dba8314dbc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lea/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/home/lea/.local/lib/python3.10/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "      <th>UMAP0</th>\n",
       "      <th>UMAP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>I3D:bio OMERO user training slides\\nHOW TO USE...</td>\n",
       "      <td>WhatIsOMERO_slide1.png</td>\n",
       "      <td>[0.4003333, -0.33649126, 0.39981106, -0.473099...</td>\n",
       "      <td>22.988615</td>\n",
       "      <td>6.322064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Disclaimer\\n• The following slides are intende...</td>\n",
       "      <td>WhatIsOMERO_slide2.png</td>\n",
       "      <td>[0.39082658, -0.28587455, 0.38830236, -0.37186...</td>\n",
       "      <td>23.344933</td>\n",
       "      <td>5.576495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Research Data Management for Bioimage Data\\nat...</td>\n",
       "      <td>WhatIsOMERO_slide3.png</td>\n",
       "      <td>[0.18631458, -0.3715705, -0.016562128, -0.6950...</td>\n",
       "      <td>23.924927</td>\n",
       "      <td>6.251481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>OMERO: An open-source software for image data ...</td>\n",
       "      <td>WhatIsOMERO_slide4.png</td>\n",
       "      <td>[0.1806397, -0.6081787, -0.6387917, -0.4824682...</td>\n",
       "      <td>23.767023</td>\n",
       "      <td>6.962986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>From isolated data silos…\\np 5 ADD LOGO SMALL</td>\n",
       "      <td>WhatIsOMERO_slide5.png</td>\n",
       "      <td>[-0.44303596, -0.50006086, 0.52318454, -0.3337...</td>\n",
       "      <td>22.896355</td>\n",
       "      <td>7.774837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>6</td>\n",
       "      <td>… to centralized, structured data management\\n...</td>\n",
       "      <td>WhatIsOMERO_slide6.png</td>\n",
       "      <td>[-0.16422987, -0.5776923, 0.6634136, -0.554668...</td>\n",
       "      <td>22.525280</td>\n",
       "      <td>7.269181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>7</td>\n",
       "      <td>OMERO at the ADD INSTITUTE HERE\\nService provi...</td>\n",
       "      <td>WhatIsOMERO_slide7.png</td>\n",
       "      <td>[-0.62620574, 0.008420461, -0.89739054, -0.598...</td>\n",
       "      <td>24.787344</td>\n",
       "      <td>6.237605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>8</td>\n",
       "      <td>Advantages of using OMERO\\n• Organize your ori...</td>\n",
       "      <td>WhatIsOMERO_slide8.png</td>\n",
       "      <td>[0.030079262, 0.27903175, -0.33694014, -0.8887...</td>\n",
       "      <td>24.230747</td>\n",
       "      <td>7.502076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WhatIsOMERO.pdf</td>\n",
       "      <td>9</td>\n",
       "      <td>Contact\\nPlease review the additional informat...</td>\n",
       "      <td>WhatIsOMERO_slide9.png</td>\n",
       "      <td>[-0.23266867, -0.5224059, 0.050569788, -0.4461...</td>\n",
       "      <td>24.280399</td>\n",
       "      <td>5.510377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pdf_filename  page_index  \\\n",
       "0  WhatIsOMERO.pdf           1   \n",
       "1  WhatIsOMERO.pdf           2   \n",
       "2  WhatIsOMERO.pdf           3   \n",
       "3  WhatIsOMERO.pdf           4   \n",
       "4  WhatIsOMERO.pdf           5   \n",
       "5  WhatIsOMERO.pdf           6   \n",
       "6  WhatIsOMERO.pdf           7   \n",
       "7  WhatIsOMERO.pdf           8   \n",
       "8  WhatIsOMERO.pdf           9   \n",
       "\n",
       "                                                text            png_filename  \\\n",
       "0  I3D:bio OMERO user training slides\\nHOW TO USE...  WhatIsOMERO_slide1.png   \n",
       "1  Disclaimer\\n• The following slides are intende...  WhatIsOMERO_slide2.png   \n",
       "2  Research Data Management for Bioimage Data\\nat...  WhatIsOMERO_slide3.png   \n",
       "3  OMERO: An open-source software for image data ...  WhatIsOMERO_slide4.png   \n",
       "4      From isolated data silos…\\np 5 ADD LOGO SMALL  WhatIsOMERO_slide5.png   \n",
       "5  … to centralized, structured data management\\n...  WhatIsOMERO_slide6.png   \n",
       "6  OMERO at the ADD INSTITUTE HERE\\nService provi...  WhatIsOMERO_slide7.png   \n",
       "7  Advantages of using OMERO\\n• Organize your ori...  WhatIsOMERO_slide8.png   \n",
       "8  Contact\\nPlease review the additional informat...  WhatIsOMERO_slide9.png   \n",
       "\n",
       "                                           embedding      UMAP0     UMAP1  \n",
       "0  [0.4003333, -0.33649126, 0.39981106, -0.473099...  22.988615  6.322064  \n",
       "1  [0.39082658, -0.28587455, 0.38830236, -0.37186...  23.344933  5.576495  \n",
       "2  [0.18631458, -0.3715705, -0.016562128, -0.6950...  23.924927  6.251481  \n",
       "3  [0.1806397, -0.6081787, -0.6387917, -0.4824682...  23.767023  6.962986  \n",
       "4  [-0.44303596, -0.50006086, 0.52318454, -0.3337...  22.896355  7.774837  \n",
       "5  [-0.16422987, -0.5776923, 0.6634136, -0.554668...  22.525280  7.269181  \n",
       "6  [-0.62620574, 0.008420461, -0.89739054, -0.598...  24.787344  6.237605  \n",
       "7  [0.030079262, 0.27903175, -0.33694014, -0.8887...  24.230747  7.502076  \n",
       "8  [-0.23266867, -0.5224059, 0.050569788, -0.4461...  24.280399  5.510377  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Convert embedding vectors to numpy array for UMAP\n",
    "embeddings = np.array(df['embedding'].tolist())\n",
    "\n",
    "# Apply UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "df['UMAP0'] = umap_embeddings[:, 0]\n",
    "df['UMAP1'] = umap_embeddings[:, 1]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6dc3c-d2f2-49fa-88d3-7aa8d3b3c675",
   "metadata": {},
   "source": [
    "### Interactively Plotting Slides and Embedding\n",
    "In the final step, we can compare different groups of slides and their content.\n",
    "\n",
    "- The plot on the right shows the 2D representation of the Embedding. With drawing a circle around datapoints you can have a look at their content at the left.\n",
    "- Slides with similar content, regarding their text, should have similar vector representations and should appear close to each other in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5b50a8-b34d-4a32-ae63-859c42a48054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(df):\n",
    "    images = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = row['png_filename']  # Access the correct row value\n",
    "        img = imread(img_path)  # Read the image\n",
    "        images.append(img)\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7325175-3ebf-4ac1-9672-5742d7e8d5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb288d53c760499e818714800f2154c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=3…"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stackview\n",
    "from skimage.io import imread\n",
    "\n",
    "stackview.sliceplot(df, get_images(df), column_x=\"UMAP0\", column_y=\"UMAP1\", zoom_factor=1.5, zoom_spline_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31c416-ed2b-4830-bc15-bec1bd62f1be",
   "metadata": {},
   "source": [
    "# Testing the plotting with a larger Slide Deck\n",
    "\n",
    "### OPTION 1: Downloading pdfs by hand and extract their Slides as pictures step by step\n",
    "To have a better idea, how this plotting is working, we now use a larger sample of PDFs from the [training material](https://zenodo.org/records/14030307) collection about Bio-Image Analysis from Robert Haase (licensed under CC-BY 4.0). We also use his implementation to [download the PDFs from Zenodo](https://github.com/haesleinhuepf/stackview/blob/main/docs/sliceplot_datagen.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4995ee-8b76-4322-a71e-08ba66e21d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': '12623730_14_Summary.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/14_Summary.pdf/content'},\n",
       " {'filename': '12623730_10_function_calling.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/10_function_calling.pdf/content'},\n",
       " {'filename': '12623730_11_prompteng_rag_finetuning.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/11_prompteng_rag_finetuning.pdf/content'},\n",
       " {'filename': '12623730_12_Vision_models.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/12_Vision_models.pdf/content'},\n",
       " {'filename': '12623730_09_Deep_Learning.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/09_Deep_Learning.pdf/content'},\n",
       " {'filename': '12623730_08_Sup_Unsup_Machine_Learning.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/08_Sup_Unsup_Machine_Learning.pdf/content'},\n",
       " {'filename': '12623730_03_RSM_Image_Processing.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/03_RSM_Image_Processing.pdf/content'},\n",
       " {'filename': '12623730_01_Introduction_BIDS_2024.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/01_Introduction_BIDS_2024.pdf/content'},\n",
       " {'filename': '12623730_13_quality_assurance.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/13_quality_assurance.pdf/content'},\n",
       " {'filename': '12623730_02_Introduction_RDM_2024.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/02_Introduction_RDM_2024.pdf/content'},\n",
       " {'filename': '12623730_04_Image_segmentation.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/04_Image_segmentation.pdf/content'},\n",
       " {'filename': '12623730_05_Surface_Recon_QA.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/05_Surface_Recon_QA.pdf/content'},\n",
       " {'filename': '12623730_07_distributed_gpu_computing.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/07_distributed_gpu_computing.pdf/content'},\n",
       " {'filename': '12623730_06_Chatbots.pdf',\n",
       "  'url': 'https://zenodo.org/api/records/12623730/files/06_Chatbots.pdf/content'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdfs_from_zenodo(record_id):\n",
    "    \"\"\"Download PDFs from Zenodo record.\"\"\"\n",
    "    base_url = f\"https://zenodo.org/api/records/{record_id}\"\n",
    "    response = requests.get(base_url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if not os.path.exists('downloads'):\n",
    "        os.makedirs('downloads')\n",
    "    \n",
    "    files_info = []\n",
    "    for file in data['files']:\n",
    "        if file['key'].endswith('.pdf'):\n",
    "            download_url = file['links']['self']\n",
    "            filename = record_id + \"_\" + file['key']\n",
    "            filepath = os.path.join('downloads', filename)\n",
    "\n",
    "            if not os.path.exists(filepath):\n",
    "                # Download file\n",
    "                response = requests.get(download_url)\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "            \n",
    "            files_info.append({'filename': filename, 'url': download_url})\n",
    "    \n",
    "    return files_info\n",
    "\n",
    "\n",
    "# Download PDFs\n",
    "files_info = download_pdfs_from_zenodo('12623730')\n",
    "files_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e1a9a-fabd-4898-a76b-5961aefa181c",
   "metadata": {},
   "source": [
    "## Saving all Slides from the pdfs to .png Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45eabde6-3356-4637-9a18-dd34b77ccc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from pdf_utilities import load_pdf, save_images, text_extraction, text_extract_from_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba90b7d-e50c-48f8-9f3a-086b693d3bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: downloads/12623730_10_function_calling.pdf\n",
      "Images for 12623730_10_function_calling.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_09_Deep_Learning.pdf\n",
      "Images for 12623730_09_Deep_Learning.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_06_Chatbots.pdf\n",
      "Images for 12623730_06_Chatbots.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_05_Surface_Recon_QA.pdf\n",
      "Images for 12623730_05_Surface_Recon_QA.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_08_Sup_Unsup_Machine_Learning.pdf\n",
      "Images for 12623730_08_Sup_Unsup_Machine_Learning.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_04_Image_segmentation.pdf\n",
      "Images for 12623730_04_Image_segmentation.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_02_Introduction_RDM_2024.pdf\n",
      "Images for 12623730_02_Introduction_RDM_2024.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_12_Vision_models.pdf\n",
      "Images for 12623730_12_Vision_models.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_11_prompteng_rag_finetuning.pdf\n",
      "Images for 12623730_11_prompteng_rag_finetuning.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_01_Introduction_BIDS_2024.pdf\n",
      "Images for 12623730_01_Introduction_BIDS_2024.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_13_quality_assurance.pdf\n",
      "Images for 12623730_13_quality_assurance.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_07_distributed_gpu_computing.pdf\n",
      "Images for 12623730_07_distributed_gpu_computing.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_03_RSM_Image_Processing.pdf\n",
      "Images for 12623730_03_RSM_Image_Processing.pdf saved successfully in downloads/images.\n",
      "Processing PDF: downloads/12623730_14_Summary.pdf\n",
      "Images for 12623730_14_Summary.pdf saved successfully in downloads/images.\n"
     ]
    }
   ],
   "source": [
    "downloads_folder = \"downloads\"\n",
    "images_folder = os.path.join(\"downloads\", \"images\")\n",
    "\n",
    "# Ensure the \"images\" folder exists\n",
    "os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over all files in the downloads folder\n",
    "for file_name in os.listdir(downloads_folder):\n",
    "    # Check if the file is a PDF\n",
    "    if file_name.lower().endswith('.pdf'):\n",
    "        pdf_path = os.path.join(downloads_folder, file_name)\n",
    "        print(f\"Processing PDF: {pdf_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Use the save_images function to save images in the \"images\" folder\n",
    "            save_images(filepath=images_folder, pdf=pdf_path, new_width=700)\n",
    "            print(f\"Images for {file_name} saved successfully in {images_folder}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e8596-d33a-42c8-88f8-c491d49c146f",
   "metadata": {},
   "source": [
    "## Extracting the text from each slide and save it to the dict_slides_text.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d34f7a-f031-411a-b6c6-490637656a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing slides for 12623730_01_Introduction_BIDS_2024...\n",
      "Processing slides for 12623730_02_Introduction_RDM_2024...\n",
      "Processing slides for 12623730_03_RSM_Image_Processing...\n",
      "Processing slides for 12623730_04_Image_segmentation...\n",
      "Processing slides for 12623730_05_Surface_Recon_QA...\n",
      "Processing slides for 12623730_06_Chatbots...\n",
      "Processing slides for 12623730_07_distributed_gpu_computing...\n",
      "Processing slides for 12623730_08_Sup_Unsup_Machine_Learning...\n",
      "Processing slides for 12623730_09_Deep_Learning...\n",
      "Processing slides for 12623730_10_function_calling...\n",
      "Processing slides for 12623730_11_prompteng_rag_finetuning...\n",
      "Processing slides for 12623730_12_Vision_models...\n",
      "Processing slides for 12623730_13_quality_assurance...\n",
      "Processing slides for 12623730_14_Summary...\n"
     ]
    }
   ],
   "source": [
    "text_extract_from_pdfs(downloads_folder=\"downloads\", yaml_file_path=\"dict_slides_text.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81af41-7a03-4806-aacd-d1f3f4ddec65",
   "metadata": {},
   "source": [
    "## Creating the pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf40f07a-564e-4fe0-ae00-d9359a5b275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# Load the YAML file containing the image paths and corresponding text\n",
    "with open(\"dict_slides_text.yml\", \"r\") as yaml_file:\n",
    "    slide_dict = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99cdd053-00de-480d-bb78-5d69fcd94af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795b0f18-2cce-45a1-988e-2ace9c78eb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing slides for 12623730_01_Introduction_BIDS_2024\n",
      "Finished processing slides for 12623730_02_Introduction_RDM_2024\n",
      "Finished processing slides for 12623730_03_RSM_Image_Processing\n",
      "Finished processing slides for 12623730_04_Image_segmentation\n",
      "Finished processing slides for 12623730_05_Surface_Recon_QA\n",
      "Finished processing slides for 12623730_06_Chatbots\n",
      "Finished processing slides for 12623730_07_distributed_gpu_computing\n",
      "Finished processing slides for 12623730_08_Sup_Unsup_Machine_Learning\n",
      "Finished processing slides for 12623730_09_Deep_Learning\n",
      "Finished processing slides for 12623730_10_function_calling\n",
      "Finished processing slides for 12623730_11_prompteng_rag_finetuning\n",
      "Finished processing slides for 12623730_12_Vision_models\n",
      "Finished processing slides for 12623730_13_quality_assurance\n",
      "Finished processing slides for 12623730_14_Summary\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "page_data = []\n",
    "last_pdf_name = None # to keep track of processing\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for png_filename, text in slide_dict.items():\n",
    "    # Get the PDF name and slide number from the filename\n",
    "    pdf_path = png_filename.split('_slide')[0]\n",
    "    pdf_name = pdf_path.replace('downloads/', '')\n",
    "\n",
    "    if pdf_name != \"WhatIsOMERO\":\n",
    "        slide_number = int(png_filename.split('_slide')[-1].split('.png')[0])\n",
    "        cleaned_png_name = re.sub(r\"^downloads/\", \"\", png_filename)    \n",
    "        # Get embedding\n",
    "        embedding = model.encode(text)\n",
    "    \n",
    "        page_data.append({\n",
    "                'pdf_filename': f'{pdf_name}.pdf',\n",
    "                'page_index': slide_number,\n",
    "                'text': text,\n",
    "                'png_filename': cleaned_png_name,\n",
    "                'embedding': embedding\n",
    "        })\n",
    "        \n",
    "    # Print message only if the PDF name has changed to keep track of the already processed pdfs\n",
    "        if pdf_name != last_pdf_name:\n",
    "            print(f\"Finished processing slides for {pdf_name}\")\n",
    "            last_pdf_name = pdf_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84abc4a0-9923-4e16-b935-b9626afa4d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide1.png</td>\n",
       "      <td>[-0.05327429, -0.044598766, 0.13387947, 0.0016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello my name is…\\n• Robert Haase\\n• Applied i...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide2.png</td>\n",
       "      <td>[0.31092378, -0.544821, 0.118443735, -0.434637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Survey\\nThink about the FAIR principles for\\nd...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide3.png</td>\n",
       "      <td>[0.023842672, 0.07436548, 0.23269953, 0.095499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>Survey\\nWhich open-source license might be\\nth...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide4.png</td>\n",
       "      <td>[0.87824875, -0.29804212, -0.18778965, -0.3386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>Survey\\nWhich topic is typically not covered i...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide5.png</td>\n",
       "      <td>[0.29033828, -0.38901746, 0.018388608, -0.0018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>65</td>\n",
       "      <td>Benchmarking vision models\\n• Prompt: „Analyse...</td>\n",
       "      <td>12623730_14_Summary_slide65.png</td>\n",
       "      <td>[0.9727107, -0.58993036, 0.11184755, -0.058897...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>66</td>\n",
       "      <td>CLIP scores\\n• Example: Prompt optimization\\nA...</td>\n",
       "      <td>12623730_14_Summary_slide66.png</td>\n",
       "      <td>[0.59838593, 0.15697823, 0.71220344, 0.2943070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>67</td>\n",
       "      <td>Testing functional correctness: HumanEval\\nPub...</td>\n",
       "      <td>12623730_14_Summary_slide67.png</td>\n",
       "      <td>[0.32575104, 0.009973767, 0.26995668, 0.425572...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>68</td>\n",
       "      <td>Modified from\\nDS-1000\\nstackoverflow\\n„functi...</td>\n",
       "      <td>12623730_14_Summary_slide68.png</td>\n",
       "      <td>[-0.055250976, 0.20740864, 0.6866639, -0.17039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>69</td>\n",
       "      <td>Exam\\n• 45 min\\n• 30 points\\n• (&lt; 30 questions...</td>\n",
       "      <td>12623730_14_Summary_slide69.png</td>\n",
       "      <td>[0.58121026, -0.5202061, 0.6575209, -0.0731819...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>863 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pdf_filename  page_index  \\\n",
       "0    12623730_01_Introduction_BIDS_2024.pdf           1   \n",
       "1    12623730_01_Introduction_BIDS_2024.pdf           2   \n",
       "2    12623730_01_Introduction_BIDS_2024.pdf           3   \n",
       "3    12623730_01_Introduction_BIDS_2024.pdf           4   \n",
       "4    12623730_01_Introduction_BIDS_2024.pdf           5   \n",
       "..                                      ...         ...   \n",
       "858                 12623730_14_Summary.pdf          65   \n",
       "859                 12623730_14_Summary.pdf          66   \n",
       "860                 12623730_14_Summary.pdf          67   \n",
       "861                 12623730_14_Summary.pdf          68   \n",
       "862                 12623730_14_Summary.pdf          69   \n",
       "\n",
       "                                                  text  \\\n",
       "0    CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...   \n",
       "1    Hello my name is…\\n• Robert Haase\\n• Applied i...   \n",
       "2    Survey\\nThink about the FAIR principles for\\nd...   \n",
       "3    Survey\\nWhich open-source license might be\\nth...   \n",
       "4    Survey\\nWhich topic is typically not covered i...   \n",
       "..                                                 ...   \n",
       "858  Benchmarking vision models\\n• Prompt: „Analyse...   \n",
       "859  CLIP scores\\n• Example: Prompt optimization\\nA...   \n",
       "860  Testing functional correctness: HumanEval\\nPub...   \n",
       "861  Modified from\\nDS-1000\\nstackoverflow\\n„functi...   \n",
       "862  Exam\\n• 45 min\\n• 30 points\\n• (< 30 questions...   \n",
       "\n",
       "                                      png_filename  \\\n",
       "0    12623730_01_Introduction_BIDS_2024_slide1.png   \n",
       "1    12623730_01_Introduction_BIDS_2024_slide2.png   \n",
       "2    12623730_01_Introduction_BIDS_2024_slide3.png   \n",
       "3    12623730_01_Introduction_BIDS_2024_slide4.png   \n",
       "4    12623730_01_Introduction_BIDS_2024_slide5.png   \n",
       "..                                             ...   \n",
       "858                12623730_14_Summary_slide65.png   \n",
       "859                12623730_14_Summary_slide66.png   \n",
       "860                12623730_14_Summary_slide67.png   \n",
       "861                12623730_14_Summary_slide68.png   \n",
       "862                12623730_14_Summary_slide69.png   \n",
       "\n",
       "                                             embedding  \n",
       "0    [-0.05327429, -0.044598766, 0.13387947, 0.0016...  \n",
       "1    [0.31092378, -0.544821, 0.118443735, -0.434637...  \n",
       "2    [0.023842672, 0.07436548, 0.23269953, 0.095499...  \n",
       "3    [0.87824875, -0.29804212, -0.18778965, -0.3386...  \n",
       "4    [0.29033828, -0.38901746, 0.018388608, -0.0018...  \n",
       "..                                                 ...  \n",
       "858  [0.9727107, -0.58993036, 0.11184755, -0.058897...  \n",
       "859  [0.59838593, 0.15697823, 0.71220344, 0.2943070...  \n",
       "860  [0.32575104, 0.009973767, 0.26995668, 0.425572...  \n",
       "861  [-0.055250976, 0.20740864, 0.6866639, -0.17039...  \n",
       "862  [0.58121026, -0.5202061, 0.6575209, -0.0731819...  \n",
       "\n",
       "[863 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.DataFrame(page_data)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fbf7d-08fe-4622-b98d-807969c6cb84",
   "metadata": {},
   "source": [
    "## Perform Dimensionality Reduction by using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3fc678-7671-4196-9ff2-8b8009da88fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lea/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "      <th>UMAP0</th>\n",
       "      <th>UMAP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide1.png</td>\n",
       "      <td>[-0.05327429, -0.044598766, 0.13387947, 0.0016...</td>\n",
       "      <td>6.225243</td>\n",
       "      <td>10.467344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello my name is…\\n• Robert Haase\\n• Applied i...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide2.png</td>\n",
       "      <td>[0.31092378, -0.544821, 0.118443735, -0.434637...</td>\n",
       "      <td>7.837998</td>\n",
       "      <td>8.350363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Survey\\nThink about the FAIR principles for\\nd...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide3.png</td>\n",
       "      <td>[0.023842672, 0.07436548, 0.23269953, 0.095499...</td>\n",
       "      <td>4.069005</td>\n",
       "      <td>11.226105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>Survey\\nWhich open-source license might be\\nth...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide4.png</td>\n",
       "      <td>[0.87824875, -0.29804212, -0.18778965, -0.3386...</td>\n",
       "      <td>2.105043</td>\n",
       "      <td>11.333110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>Survey\\nWhich topic is typically not covered i...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide5.png</td>\n",
       "      <td>[0.29033828, -0.38901746, 0.018388608, -0.0018...</td>\n",
       "      <td>4.592541</td>\n",
       "      <td>11.582233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>65</td>\n",
       "      <td>Benchmarking vision models\\n• Prompt: „Analyse...</td>\n",
       "      <td>12623730_14_Summary_slide65.png</td>\n",
       "      <td>[0.9727107, -0.58993036, 0.11184755, -0.058897...</td>\n",
       "      <td>7.367217</td>\n",
       "      <td>9.412332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>66</td>\n",
       "      <td>CLIP scores\\n• Example: Prompt optimization\\nA...</td>\n",
       "      <td>12623730_14_Summary_slide66.png</td>\n",
       "      <td>[0.59838593, 0.15697823, 0.71220344, 0.2943070...</td>\n",
       "      <td>5.801350</td>\n",
       "      <td>7.999154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>67</td>\n",
       "      <td>Testing functional correctness: HumanEval\\nPub...</td>\n",
       "      <td>12623730_14_Summary_slide67.png</td>\n",
       "      <td>[0.32575104, 0.009973767, 0.26995668, 0.425572...</td>\n",
       "      <td>5.278358</td>\n",
       "      <td>8.707326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>68</td>\n",
       "      <td>Modified from\\nDS-1000\\nstackoverflow\\n„functi...</td>\n",
       "      <td>12623730_14_Summary_slide68.png</td>\n",
       "      <td>[-0.055250976, 0.20740864, 0.6866639, -0.17039...</td>\n",
       "      <td>8.575429</td>\n",
       "      <td>6.964963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>69</td>\n",
       "      <td>Exam\\n• 45 min\\n• 30 points\\n• (&lt; 30 questions...</td>\n",
       "      <td>12623730_14_Summary_slide69.png</td>\n",
       "      <td>[0.58121026, -0.5202061, 0.6575209, -0.0731819...</td>\n",
       "      <td>5.938373</td>\n",
       "      <td>9.811185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>863 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pdf_filename  page_index  \\\n",
       "0    12623730_01_Introduction_BIDS_2024.pdf           1   \n",
       "1    12623730_01_Introduction_BIDS_2024.pdf           2   \n",
       "2    12623730_01_Introduction_BIDS_2024.pdf           3   \n",
       "3    12623730_01_Introduction_BIDS_2024.pdf           4   \n",
       "4    12623730_01_Introduction_BIDS_2024.pdf           5   \n",
       "..                                      ...         ...   \n",
       "858                 12623730_14_Summary.pdf          65   \n",
       "859                 12623730_14_Summary.pdf          66   \n",
       "860                 12623730_14_Summary.pdf          67   \n",
       "861                 12623730_14_Summary.pdf          68   \n",
       "862                 12623730_14_Summary.pdf          69   \n",
       "\n",
       "                                                  text  \\\n",
       "0    CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...   \n",
       "1    Hello my name is…\\n• Robert Haase\\n• Applied i...   \n",
       "2    Survey\\nThink about the FAIR principles for\\nd...   \n",
       "3    Survey\\nWhich open-source license might be\\nth...   \n",
       "4    Survey\\nWhich topic is typically not covered i...   \n",
       "..                                                 ...   \n",
       "858  Benchmarking vision models\\n• Prompt: „Analyse...   \n",
       "859  CLIP scores\\n• Example: Prompt optimization\\nA...   \n",
       "860  Testing functional correctness: HumanEval\\nPub...   \n",
       "861  Modified from\\nDS-1000\\nstackoverflow\\n„functi...   \n",
       "862  Exam\\n• 45 min\\n• 30 points\\n• (< 30 questions...   \n",
       "\n",
       "                                      png_filename  \\\n",
       "0    12623730_01_Introduction_BIDS_2024_slide1.png   \n",
       "1    12623730_01_Introduction_BIDS_2024_slide2.png   \n",
       "2    12623730_01_Introduction_BIDS_2024_slide3.png   \n",
       "3    12623730_01_Introduction_BIDS_2024_slide4.png   \n",
       "4    12623730_01_Introduction_BIDS_2024_slide5.png   \n",
       "..                                             ...   \n",
       "858                12623730_14_Summary_slide65.png   \n",
       "859                12623730_14_Summary_slide66.png   \n",
       "860                12623730_14_Summary_slide67.png   \n",
       "861                12623730_14_Summary_slide68.png   \n",
       "862                12623730_14_Summary_slide69.png   \n",
       "\n",
       "                                             embedding     UMAP0      UMAP1  \n",
       "0    [-0.05327429, -0.044598766, 0.13387947, 0.0016...  6.225243  10.467344  \n",
       "1    [0.31092378, -0.544821, 0.118443735, -0.434637...  7.837998   8.350363  \n",
       "2    [0.023842672, 0.07436548, 0.23269953, 0.095499...  4.069005  11.226105  \n",
       "3    [0.87824875, -0.29804212, -0.18778965, -0.3386...  2.105043  11.333110  \n",
       "4    [0.29033828, -0.38901746, 0.018388608, -0.0018...  4.592541  11.582233  \n",
       "..                                                 ...       ...        ...  \n",
       "858  [0.9727107, -0.58993036, 0.11184755, -0.058897...  7.367217   9.412332  \n",
       "859  [0.59838593, 0.15697823, 0.71220344, 0.2943070...  5.801350   7.999154  \n",
       "860  [0.32575104, 0.009973767, 0.26995668, 0.425572...  5.278358   8.707326  \n",
       "861  [-0.055250976, 0.20740864, 0.6866639, -0.17039...  8.575429   6.964963  \n",
       "862  [0.58121026, -0.5202061, 0.6575209, -0.0731819...  5.938373   9.811185  \n",
       "\n",
       "[863 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Convert embedding vectors to numpy array for UMAP\n",
    "embeddings = np.array(df_all['embedding'].tolist())\n",
    "\n",
    "# Apply UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "\n",
    "df_all['UMAP0'] = umap_embeddings[:, 0]\n",
    "df_all['UMAP1'] = umap_embeddings[:, 1]\n",
    "\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1316e-30f3-47ac-a5f2-d103bbc29547",
   "metadata": {},
   "source": [
    "#### Upload Data\n",
    "As this file can get quite big, depending on the number of pdfs we feed in, it might be helpful to store it online rather than on disc. A good option would be for example to store it with Huggingface.\n",
    "To do so you first need to install this option with:\n",
    "\n",
    "`pip install datasets`\n",
    "\n",
    "You also have to create a [Huggingface Token](https://huggingface.co/docs/hub/security-tokens) and set this as a environment variable. To get more information on how to do that, that check the [ReadMe](https://github.com/NFDI4BIOIMAGE/SlideInsight/blob/main/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e17f41-8ab0-45fc-9d63-16693ef484d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "#Authenticate your current session\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd866e-abeb-49d1-ac47-e329e679d768",
   "metadata": {},
   "source": [
    "To save the dictonary, first create a HF Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3542185-dcb4-4e47-9b05-c1f47596bbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pdf_filename', 'page_index', 'text', 'png_filename', 'embedding', 'UMAP0', 'UMAP1'],\n",
       "    num_rows: 863\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create a Hugging Face dataset from the DataFrame\n",
    "dataset = Dataset.from_pandas(df_all)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b5bed4-bf95-4633-bb9a-4e80dc1875e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf4a0d58f7a4591b415f426e6297e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c52f5c9daa04eb48f72b4e4432248fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/lea-33/SlightInsight_Data/commit/ddee771036f208cb2551eaf580bb78de161c9285', commit_message='Upload dataset', commit_description='', oid='ddee771036f208cb2551eaf580bb78de161c9285', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/lea-33/SlightInsight_Data', endpoint='https://huggingface.co', repo_type='dataset', repo_id='lea-33/SlightInsight_Data'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the dataset to huggingface\n",
    "dataset.push_to_hub(\"lea-33/SlightInsight_Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fed1f4-9d91-4654-85b0-ecd3390d9897",
   "metadata": {},
   "source": [
    "#### Upload Images\n",
    "To save the corresponding Images, another Dataset is created and pushed to HF like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "359886fa-aa1b-4ec8-a841-f6d309e6c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image'],\n",
      "    num_rows: 863\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Features, Image\n",
    "import os\n",
    "from natsort import natsorted\n",
    "\n",
    "image_folder = \"downloads/images\"\n",
    "\n",
    "# List and filter only valid image files\n",
    "valid_extensions = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\", \".webp\"}  # Add more extensions if needed\n",
    "image_paths = natsorted(\n",
    "    [\n",
    "        os.path.join(image_folder, fname)\n",
    "        for fname in os.listdir(image_folder)\n",
    "        if os.path.isfile(os.path.join(image_folder, fname)) and os.path.splitext(fname)[1].lower() in valid_extensions\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a dataset\n",
    "data = [{\"image\": path} for path in image_paths]\n",
    "\n",
    "# This specifies the column contains images\n",
    "features = Features({\n",
    "    \"image\": Image(),\n",
    "})\n",
    "\n",
    "dataset = Dataset.from_list(data, features=features)\n",
    "\n",
    "# Preview the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc5a200-e290-4f13-ba59-7739f003002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d06ed1b22a41878768c583596fc592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc9384b71441868ad30ef31b6a7460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/863 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4de5c3a6804d48b9405e6647870af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/lea-33/SlideInsight_Images/commit/c0a1d3e674e1b5f26383d3d88ab89038b8e29ae7', commit_message='Upload dataset', commit_description='', oid='c0a1d3e674e1b5f26383d3d88ab89038b8e29ae7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/lea-33/SlideInsight_Images', endpoint='https://huggingface.co', repo_type='dataset', repo_id='lea-33/SlideInsight_Images'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"lea-33/SlideInsight_Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c576db9b-4b8f-4445-b1e0-871224004620",
   "metadata": {},
   "source": [
    "### OPTION 2: Loading the dict and corresponding Images from Huggingface\n",
    "After the dictionary was successfully stored on Huggingface, we can skip the whole downloading and embedding calculation part and directly work with the dictionary/images by loading them from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848bd41f-e758-49ec-a3e5-56a31f3f1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_loaded = pd.read_parquet(\"hf://datasets/lea-33/SlightInsight_Data/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e48e10d4-37a0-4e3c-a4a8-11e3d813734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_filename</th>\n",
       "      <th>page_index</th>\n",
       "      <th>text</th>\n",
       "      <th>png_filename</th>\n",
       "      <th>embedding</th>\n",
       "      <th>UMAP0</th>\n",
       "      <th>UMAP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide1.png</td>\n",
       "      <td>[-0.05327429, -0.044598766, 0.13387947, 0.0016...</td>\n",
       "      <td>6.225243</td>\n",
       "      <td>10.467344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello my name is…\\n• Robert Haase\\n• Applied i...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide2.png</td>\n",
       "      <td>[0.31092378, -0.544821, 0.118443735, -0.434637...</td>\n",
       "      <td>7.837998</td>\n",
       "      <td>8.350363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>Survey\\nThink about the FAIR principles for\\nd...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide3.png</td>\n",
       "      <td>[0.023842672, 0.07436548, 0.23269953, 0.095499...</td>\n",
       "      <td>4.069005</td>\n",
       "      <td>11.226105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>Survey\\nWhich open-source license might be\\nth...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide4.png</td>\n",
       "      <td>[0.87824875, -0.29804212, -0.18778965, -0.3386...</td>\n",
       "      <td>2.105043</td>\n",
       "      <td>11.333110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12623730_01_Introduction_BIDS_2024.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>Survey\\nWhich topic is typically not covered i...</td>\n",
       "      <td>12623730_01_Introduction_BIDS_2024_slide5.png</td>\n",
       "      <td>[0.29033828, -0.38901746, 0.018388608, -0.0018...</td>\n",
       "      <td>4.592541</td>\n",
       "      <td>11.582233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>65</td>\n",
       "      <td>Benchmarking vision models\\n• Prompt: „Analyse...</td>\n",
       "      <td>12623730_14_Summary_slide65.png</td>\n",
       "      <td>[0.9727107, -0.58993036, 0.11184755, -0.058897...</td>\n",
       "      <td>7.367217</td>\n",
       "      <td>9.412332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>66</td>\n",
       "      <td>CLIP scores\\n• Example: Prompt optimization\\nA...</td>\n",
       "      <td>12623730_14_Summary_slide66.png</td>\n",
       "      <td>[0.59838593, 0.15697823, 0.71220344, 0.2943070...</td>\n",
       "      <td>5.801350</td>\n",
       "      <td>7.999154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>67</td>\n",
       "      <td>Testing functional correctness: HumanEval\\nPub...</td>\n",
       "      <td>12623730_14_Summary_slide67.png</td>\n",
       "      <td>[0.32575104, 0.009973767, 0.26995668, 0.425572...</td>\n",
       "      <td>5.278358</td>\n",
       "      <td>8.707326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>68</td>\n",
       "      <td>Modified from\\nDS-1000\\nstackoverflow\\n„functi...</td>\n",
       "      <td>12623730_14_Summary_slide68.png</td>\n",
       "      <td>[-0.055250976, 0.20740864, 0.6866639, -0.17039...</td>\n",
       "      <td>8.575429</td>\n",
       "      <td>6.964963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>12623730_14_Summary.pdf</td>\n",
       "      <td>69</td>\n",
       "      <td>Exam\\n• 45 min\\n• 30 points\\n• (&lt; 30 questions...</td>\n",
       "      <td>12623730_14_Summary_slide69.png</td>\n",
       "      <td>[0.58121026, -0.5202061, 0.6575209, -0.0731819...</td>\n",
       "      <td>5.938373</td>\n",
       "      <td>9.811185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>863 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pdf_filename  page_index  \\\n",
       "0    12623730_01_Introduction_BIDS_2024.pdf           1   \n",
       "1    12623730_01_Introduction_BIDS_2024.pdf           2   \n",
       "2    12623730_01_Introduction_BIDS_2024.pdf           3   \n",
       "3    12623730_01_Introduction_BIDS_2024.pdf           4   \n",
       "4    12623730_01_Introduction_BIDS_2024.pdf           5   \n",
       "..                                      ...         ...   \n",
       "858                 12623730_14_Summary.pdf          65   \n",
       "859                 12623730_14_Summary.pdf          66   \n",
       "860                 12623730_14_Summary.pdf          67   \n",
       "861                 12623730_14_Summary.pdf          68   \n",
       "862                 12623730_14_Summary.pdf          69   \n",
       "\n",
       "                                                  text  \\\n",
       "0    CENTER FOR SCALABLE DATA ANALYTICS\\nAND ARTIFI...   \n",
       "1    Hello my name is…\\n• Robert Haase\\n• Applied i...   \n",
       "2    Survey\\nThink about the FAIR principles for\\nd...   \n",
       "3    Survey\\nWhich open-source license might be\\nth...   \n",
       "4    Survey\\nWhich topic is typically not covered i...   \n",
       "..                                                 ...   \n",
       "858  Benchmarking vision models\\n• Prompt: „Analyse...   \n",
       "859  CLIP scores\\n• Example: Prompt optimization\\nA...   \n",
       "860  Testing functional correctness: HumanEval\\nPub...   \n",
       "861  Modified from\\nDS-1000\\nstackoverflow\\n„functi...   \n",
       "862  Exam\\n• 45 min\\n• 30 points\\n• (< 30 questions...   \n",
       "\n",
       "                                      png_filename  \\\n",
       "0    12623730_01_Introduction_BIDS_2024_slide1.png   \n",
       "1    12623730_01_Introduction_BIDS_2024_slide2.png   \n",
       "2    12623730_01_Introduction_BIDS_2024_slide3.png   \n",
       "3    12623730_01_Introduction_BIDS_2024_slide4.png   \n",
       "4    12623730_01_Introduction_BIDS_2024_slide5.png   \n",
       "..                                             ...   \n",
       "858                12623730_14_Summary_slide65.png   \n",
       "859                12623730_14_Summary_slide66.png   \n",
       "860                12623730_14_Summary_slide67.png   \n",
       "861                12623730_14_Summary_slide68.png   \n",
       "862                12623730_14_Summary_slide69.png   \n",
       "\n",
       "                                             embedding     UMAP0      UMAP1  \n",
       "0    [-0.05327429, -0.044598766, 0.13387947, 0.0016...  6.225243  10.467344  \n",
       "1    [0.31092378, -0.544821, 0.118443735, -0.434637...  7.837998   8.350363  \n",
       "2    [0.023842672, 0.07436548, 0.23269953, 0.095499...  4.069005  11.226105  \n",
       "3    [0.87824875, -0.29804212, -0.18778965, -0.3386...  2.105043  11.333110  \n",
       "4    [0.29033828, -0.38901746, 0.018388608, -0.0018...  4.592541  11.582233  \n",
       "..                                                 ...       ...        ...  \n",
       "858  [0.9727107, -0.58993036, 0.11184755, -0.058897...  7.367217   9.412332  \n",
       "859  [0.59838593, 0.15697823, 0.71220344, 0.2943070...  5.801350   7.999154  \n",
       "860  [0.32575104, 0.009973767, 0.26995668, 0.425572...  5.278358   8.707326  \n",
       "861  [-0.055250976, 0.20740864, 0.6866639, -0.17039...  8.575429   6.964963  \n",
       "862  [0.58121026, -0.5202061, 0.6575209, -0.0731819...  5.938373   9.811185  \n",
       "\n",
       "[863 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b0ff383-0bf4-4569-8efc-064a34c47a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "def get_all_images(dataset_name, split=\"train\"):\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(dataset_name, split=split, streaming=True)\n",
    "\n",
    "    # Extract images\n",
    "    images = []\n",
    "    for sample in dataset:\n",
    "        img = sample[\"image\"]  # Access the image\n",
    "        images.append(np.array(img))  # Convert the PIL image to a NumPy array\n",
    "    \n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e462705-3dd0-484d-baf6-1427159888d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8237360fb34f4a319ec113cf2267dde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"lea-33/SlideInsight_Images\"\n",
    "images = get_all_images(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d875b7a-5ebf-444b-bca7-61798b6651d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259b2e8a546e44c5af7a493610bf0ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=3…"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stackview\n",
    "from skimage.io import imread\n",
    "\n",
    "stackview.sliceplot(df_loaded, images, column_x=\"UMAP0\", column_y=\"UMAP1\", zoom_factor=1, zoom_spline_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3171369-27d5-4c39-81ee-da8dd58debd4",
   "metadata": {},
   "source": [
    "### Optionally: Deleting the pdfs and images again from your local disc (by deleting the whole downloads folder that was just created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8f89e87-10f7-4c2f-9685-5f839117d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6434e314-a75a-4747-8350-521963ed8c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted the folder: downloads\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path\n",
    "folder_path = \"downloads\"\n",
    "\n",
    "try:\n",
    "    # Delete the entire folder and its contents\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"Deleted the folder: {folder_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting folder {folder_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
